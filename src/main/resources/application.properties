spring.application.name=incidentaiapp
llm.api.url=https://api.groq.com/openai/v1/chat/completions
llm.model.name=llama-3.3-70b-versatile
llm.response.timeout.seconds=30
llm.max.tokens=2048
llm.temperature=0.7